{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haniklakhe18/Temperature_analysis/blob/main/1_CM_all_Indices_computation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_9xHTrgJSPc",
        "outputId": "38d7e90f-398b-431d-b2b2-d58ee1e7c9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1O-MFgaD1XScZMZWPVHajo8pnhSpkoNc-/GCM\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/GCM'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CM = ['ACCESS-CM2','ACCESS-ESM1-5','BCC-CSM2-MR','CanESM5',\n",
        "      'EC-Earth3','EC-Earth3-Veg','INM-CM4-8','INM-CM5-0',\n",
        "      'MPI-ESM1-2-LR','MPI-ESM1-2-HR','MRI-ESM2-0','NorESM2-LM',\n",
        "     'NorESM2-MM']\n",
        "#CM = ['ACCESS-CM2']\n",
        "scenario = ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']"
      ],
      "metadata": {
        "id": "6P_d-3VfJc-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indices (Tmax, Tmax1, Tmin, Tmin1, Tavg1, file_path):\n",
        "  #summer days\n",
        "  SU = Tmax1>25\n",
        "  SU['Year'] = Tmax['Year']\n",
        "  SU = SU.groupby(['Year']).sum()\n",
        "  SU.to_csv (main_path + file_path + 'SU.csv', index = True)\n",
        "\n",
        "  #Tropical nights (TN)\n",
        "  TN = Tmin1>20\n",
        "  TN ['Year'] = Tmin['Year']\n",
        "  TN = TN.groupby(['Year']).sum()\n",
        "  TN.to_csv (main_path + file_path + 'TN.csv', index = True)\n",
        "\n",
        "  #Ice days\n",
        "  ID = Tmax1<0\n",
        "  ID ['Year'] = Tmax['Year']\n",
        "  ID = ID.groupby(['Year']).sum()\n",
        "  ID.to_csv (main_path + file_path + 'ID.csv', index = True)\n",
        "\n",
        "  #Frost days (FD)\n",
        "  FD = Tmin1<0\n",
        "  FD ['Year'] = Tmin['Year']\n",
        "  FD = FD.groupby(['Year']).sum()\n",
        "  FD.to_csv (main_path + file_path +'FD.csv', index = True)\n",
        "\n",
        "  #Minimum temperature below 2 degree celsius (TNlt2)\n",
        "  TNlt2 = Tmin1<2\n",
        "  TNlt2 ['Year'] = Tmin['Year']\n",
        "  TNlt2 = TNlt2.groupby(['Year']).sum()\n",
        "  TNlt2.to_csv (main_path + file_path + 'TNlt2.csv', index = True)\n",
        "\n",
        "  #Minimum temperature below -2 degree celsius (TNltm2)\n",
        "  TNltm2 = Tmin1<-2\n",
        "  TNltm2 ['Year'] = Tmin['Year']\n",
        "  TNltm2 = TNltm2.groupby(['Year']).sum()\n",
        "  TNltm2.to_csv (main_path + file_path + 'TNltm2.csv', index = True)\n",
        "\n",
        "  #Temperature below -20 degree celsius (TNltm20)\n",
        "  TNltm20 = Tmin1<-20\n",
        "  TNltm20 ['Year'] = Tmin['Year']\n",
        "  TNltm20 = TNltm20.groupby(['Year']).sum()\n",
        "\n",
        "  TNltm20.to_csv (main_path + file_path + 'TNltm20.csv', index = True)\n",
        "\n",
        "  #Durinal temperature range (DTR) or Mean differenc of Tmax and Tmin\n",
        "  DTR = Tmax1 - Tmin1\n",
        "  DTR ['Year'] = Tmax['Year']\n",
        "  DTR = DTR.groupby(['Year']).mean()\n",
        "\n",
        "  DTR.to_csv (main_path + file_path + 'DTR.csv', index = True)\n",
        "\n",
        "  #Lowest Tmax (TXn)\n",
        "  TXn = Tmax1.copy()\n",
        "  TXn ['Year'] = Tmax['Year']\n",
        "  TXn = TXn.groupby(['Year']).min()\n",
        "\n",
        "  TXn.to_csv (main_path + file_path + 'TXn.csv', index = True)\n",
        "\n",
        "  #Lowest Tmin (TNn)\n",
        "  TNn = Tmin1.copy()\n",
        "  TNn ['Year'] = Tmin['Year']\n",
        "  TNn = TNn.groupby(['Year']).min()\n",
        "\n",
        "  TNn.to_csv (main_path + file_path + 'TNn.csv', index = True)\n",
        "\n",
        "  #Highest Tmax (TXx)\n",
        "  TXx = Tmax1.copy()\n",
        "  TXx ['Year'] = Tmax['Year']\n",
        "  TXx = TXx.groupby(['Year']).max()\n",
        "\n",
        "  TXx.to_csv (main_path + file_path + 'TXx.csv', index = True)\n",
        "\n",
        "  #Highest Tmin (TNx)\n",
        "  TNx = Tmin1.copy()\n",
        "  TNx ['Year'] = Tmin['Year']\n",
        "  TNx = TXx.groupby(['Year']).max()\n",
        "\n",
        "  TNx.to_csv (main_path + file_path + 'TNx.csv', index = True)\n",
        "\n",
        "  #Mean daily mean temperature\n",
        "  TMm = Tavg1.copy()\n",
        "  TMm ['Year'] = Tmin['Year']\n",
        "  TMm = TMm.groupby(['Year']).mean()\n",
        "\n",
        "  TMm.to_csv (main_path + file_path + 'TMm.csv', index = True)\n",
        "\n",
        "  #Mean daily max temperature\n",
        "  TXm = Tmax1.copy()\n",
        "  TXm ['Year'] = Tmax['Year']\n",
        "  TXm = TXm.groupby(['Year']).mean()\n",
        "\n",
        "  TXm.to_csv (main_path + file_path + 'TXm.csv', index = True)\n",
        "\n",
        "  #Mean daily min temperature\n",
        "  TNm = Tmin1.copy()\n",
        "  TNm ['Year'] = Tmin['Year']\n",
        "  TNm = TNm.groupby(['Year']).mean()\n",
        "\n",
        "  TNm.to_csv (main_path + file_path + 'TNm.csv', index = True)\n",
        "\n",
        "  #Days with Tavg>=5 (TMge5)\n",
        "  TMge5 = Tavg1>=5\n",
        "  TMge5 ['Year'] = Tmin['Year']\n",
        "  TMge5 = TMge5.groupby(['Year']).sum()\n",
        "\n",
        "  TMge5.to_csv (main_path + file_path + 'TMge5.csv', index = True)\n",
        "\n",
        "  #Days with Tavg<5 (TMlt5)\n",
        "  TMlt5 = (Tavg1<5).astype(int)\n",
        "  TMlt5 ['Year'] = Tmin['Year']\n",
        "  TMlt5 = TMlt5.groupby(['Year']).sum()\n",
        "\n",
        "  TMlt5.to_csv (main_path + file_path + 'TMlt5.csv', index = True)\n",
        "\n",
        "  #Days with Tavg>=10 (TMge10)\n",
        "  TMge10 = Tavg1>=10\n",
        "  TMge10 ['Year'] = Tmin['Year']\n",
        "  TMge10 = TMge10.groupby(['Year']).sum()\n",
        "  TMge10.to_csv (main_path + file_path + 'TMge10.csv', index = True)\n",
        "\n",
        "  #Days with Tavg<10 (TMlt10)\n",
        "  TMlt10 = (Tavg1<10).astype(int)\n",
        "  TMlt10 ['Year'] = Tmin['Year']\n",
        "  TMlt10 = TMlt10.groupby(['Year']).sum()\n",
        "\n",
        "  TMlt10.to_csv (main_path + file_path + 'TMlt10.csv', index = True)\n",
        "\n",
        "  #Days with Tavg>=30 (TMge30)\n",
        "  TMge30 = Tavg1>=30\n",
        "  TMge30 ['Year'] = Tmin['Year']\n",
        "  TMge30 = TMge30.groupby(['Year']).sum()\n",
        "  TMge30.to_csv (main_path + file_path + 'TMge30.csv', index = True)\n",
        "\n",
        "  #Days with Tavg>=35 (TMge35)\n",
        "  TMge35 = Tavg1>=35\n",
        "  TMge35 ['Year'] = Tmin['Year']\n",
        "  TMge35 = TMge35.groupby(['Year']).sum()\n",
        "  TMge35.to_csv (main_path + file_path + 'TMge35.csv', index = True)\n",
        "\n",
        "  #Warm nights - percentage of days when tmin >90 percentile\n",
        "  Ntg90p = Tmin1.copy(deep = True)\n",
        "\n",
        "  for i in range(0,len(Tmin1.columns)):\n",
        "      Ntg90p_temp = np.percentile(Tmin1.iloc[:,i],90)\n",
        "      Ntg90p.iloc[:,i] = Ntg90p_temp\n",
        "  Ntg90p\n",
        "\n",
        "  # value less than threshold converted to zero\n",
        "  Ntg90p = (Tmin1 > Ntg90p) #boolean output zero and one,\n",
        "  Ntg90p ['Year'] = Tmin['Year']\n",
        "  Ntg90p = Ntg90p.groupby(['Year']).sum()\n",
        "  Ntg90p = Ntg90p/365*100\n",
        "\n",
        "  Ntg90p.to_csv (main_path + file_path + 'Ntg90p.csv', index = True)\n",
        "\n",
        "  #Warm days - percentage of days when tmax>90 percentile\n",
        "  Xtg90p = Tmax1.copy(deep = True)\n",
        "\n",
        "  for i in range(0,len(Tmax1.columns)):\n",
        "      Xtg90p_temp = np.percentile(Tmax1.iloc[:,i],90)\n",
        "      Xtg90p.iloc[:,i] = Xtg90p_temp\n",
        "\n",
        "  # value less than threshold converted to zero\n",
        "  Xtg90p = (Tmax1 > Xtg90p) #boolean output zero and one,\n",
        "  Xtg90p ['Year'] = Tmax['Year']\n",
        "  Xtg90p = Xtg90p.groupby(['Year']).sum()\n",
        "  Xtg90p = Xtg90p/365*100\n",
        "\n",
        "  Xtg90p.to_csv (main_path + file_path + 'Xtg90p.csv', index = True)\n",
        "\n",
        "  #above average temperature - percentage of days when tmax> 50 percentile\n",
        "  Xtg50p = Tmax1.copy(deep = True)\n",
        "  for i in range(0,len(Tmax1.columns)):\n",
        "      Xtg50p_temp = np.percentile(Tmax1.iloc[:,i],50)\n",
        "      Xtg50p.iloc[:,i] = Xtg50p_temp\n",
        "\n",
        "  # value less than threshold converted to zero\n",
        "  Xtg50p = (Tmax1 > Xtg50p)#boolean output zero and one,\n",
        "  Xtg50p ['Year'] = Tmax['Year']\n",
        "  Xtg50p = Xtg50p.groupby(['Year']).sum()\n",
        "  Xtg50p = Xtg50p/365*100\n",
        "\n",
        "  Xtg50p.to_csv(main_path + file_path + 'Xtg50p.csv', index = True)\n",
        "\n",
        "  #cold nights - percentage of days when tmin <10 percentile\n",
        "  Nlt10p = Tmin1.copy(deep = True)\n",
        "\n",
        "  for i in range(0,len(Tmin1.columns)):\n",
        "      Nlt10p_temp = np.percentile(Tmin1.iloc[:,i],10)\n",
        "      Nlt10p.iloc[:,i] = Nlt10p_temp\n",
        "\n",
        "  # value less than threshold converted to zero\n",
        "  Nlt10p = (Tmin1 < Nlt10p)#boolean output zero and one,\n",
        "  Nlt10p ['Year'] = Tmin['Year']\n",
        "  Nlt10p = Nlt10p.groupby(['Year']).sum()\n",
        "  Nlt10p = Nlt10p/365*100\n",
        "\n",
        "  Nlt10p.to_csv (main_path + file_path + 'Nlt10p.csv', index = True)\n",
        "\n",
        "  #cold days - percentage of days when tmax<10 percentile\n",
        "  Xlt10p = Tmax1.copy(deep = True)\n",
        "  for i in range(0,len(Tmax1.columns)):\n",
        "      Xlt10p_temp = np.percentile(Tmax1.iloc[:,i],10)\n",
        "      Xlt10p.iloc[:,i] = Xlt10p_temp\n",
        "\n",
        "  # value less than threshold converted to zero\n",
        "  Xlt10p = (Tmax1 < Xlt10p)#boolean output zero and one,\n",
        "  Xlt10p ['Year'] = Tmax['Year']\n",
        "  Xlt10p = Xlt10p.groupby(['Year']).sum()\n",
        "  Xlt10p = Xlt10p/365*100\n",
        "\n",
        "  Xlt10p.to_csv(main_path + file_path + 'Xlt10p.csv', index = True)\n",
        "\n",
        "  #very warmday threshold - 95 percentile of Tmax\n",
        "  X95p = Tmax1.copy()\n",
        "  X95p ['Year'] = Tmax['Year']\n",
        "  X95p = X95p.groupby(['Year']).quantile(q=0.95)\n",
        "\n",
        "  X95p.to_csv (main_path + file_path + 'X95p.csv', index = True)\n",
        "\n",
        "  #Warm spell duration Index - count of days when at least 6 consecutive days with Tmax > 90 percentile\n",
        "  Xt90p = Tmax1.copy(deep = True)\n",
        "  for i in range(0,len(Tmax1.columns)):\n",
        "      Xt90p_temp = np.percentile(Tmax1.iloc[:,i],90)\n",
        "      Xt90p.iloc[:,i] = Xt90p_temp\n",
        "  df_WSDI = (Tmax1 > Xt90p)#boolean output zero and one,\n",
        "\n",
        "  df_WSDI.cumsum().where(~df_WSDI).ffill().fillna(0)\n",
        "  df_WSDI = df_WSDI.cumsum()-df_WSDI.cumsum().where(~df_WSDI).ffill().fillna(0)\n",
        "\n",
        "  Xtatleast6 = (df_WSDI>= 6).astype(int)\n",
        "\n",
        "  Xtatleast6 ['Year'] = Tmax['Year']\n",
        "  WSDI = Xtatleast6.groupby(['Year']).sum()\n",
        "\n",
        "  WSDI.to_csv(main_path + file_path + 'WSDI.csv', index = True)\n",
        "\n",
        "  #Cold spell duration Index - count of days when at least 6 consecutive days with tmin < 10 percentile\n",
        "  Nt10p = Tmin1.copy(deep = True)\n",
        "  for i in range(0,len(Tmin1.columns)):\n",
        "      Nt10p_temp = np.percentile(Tmin1.iloc[:,i],10)\n",
        "      Nt10p.iloc[:,i] = Nt10p_temp\n",
        "  df_CSDI = (Tmin1<Nt10p)#boolean output zero and one,\n",
        "\n",
        "  df_CSDI.cumsum().where(~df_CSDI).ffill().fillna(0)\n",
        "  df_CSDI = df_CSDI.cumsum()-df_CSDI.cumsum().where(~df_CSDI).ffill().fillna(0)\n",
        "\n",
        "  Ntatleast6 = (df_CSDI>= 6).astype(int)\n",
        "  Ntatleast6 ['Year'] = Tmin['Year']\n",
        "  CSDI = Ntatleast6.groupby(['Year']).sum()\n",
        "\n",
        "  CSDI.to_csv(main_path + file_path + 'CSDI.csv', index = True)\n",
        "  return"
      ],
      "metadata": {
        "id": "qTKH76N0Ku7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "main_path = '/content/drive/My Drive/Indices/Ensemble/Computed_Indices/'\n",
        "for n in tqdm(range (0, len(CM))):\n",
        "  for i in range (0, len(scenario)):\n",
        "\n",
        "    file_path = str(CM[n]) + '/'+ str(scenario[i]) + '/'\n",
        "\n",
        "    # Daily temperature data\n",
        "    Tmax = pd.read_csv(file_path + 'TMaxData', sep=\" \", header=None)\n",
        "    Tmin = pd.read_csv(file_path +  'TMinData', sep=\" \", header=None)\n",
        "\n",
        "    #skipped long and lat row\n",
        "    Tmax = Tmax.iloc[2:,:]\n",
        "    Tmin = Tmin.iloc[2:,:]\n",
        "\n",
        "    #In order to make the column name as desired\n",
        "    col_names = ['Year','Month','Day'] + np.arange(1, len(Tmax.columns)-3 + 1).tolist()\n",
        "\n",
        "    for j in enumerate(Tmax.columns):\n",
        "      Tmax.columns = col_names\n",
        "\n",
        "    for j in enumerate(Tmin.columns):\n",
        "      Tmin.columns = col_names\n",
        "\n",
        "    #skipped first three columns\n",
        "    Tmax1 = Tmax.iloc[:,3:]\n",
        "    Tmin1 = Tmin.iloc[:,3:]\n",
        "    is_value_present_min = (Tmin1 == -273.15).any().any()\n",
        "    print(is_value_present_min)\n",
        "\n",
        "    is_value_present_max = (Tmax1 == -273.15).any().any()\n",
        "    print(is_value_present_max)\n",
        "\n",
        "    #Replace -273.15 by np.nan\n",
        "    Tmax1 = Tmax1.replace(-273.15,np.nan)\n",
        "    Tmin1 = Tmin1.replace(-273.15,np.nan)\n",
        "\n",
        "    #fill data gaps by using a forward linear interpolation\n",
        "    Tmax1 = Tmax1.interpolate(method ='linear', limit_direction = 'forward')\n",
        "    Tmin1 = Tmin1.interpolate(method ='linear', limit_direction = 'forward')\n",
        "\n",
        "    Tavg1 = (Tmax1 + Tmin1)/2\n",
        "\n",
        "    indices (Tmax, Tmax1, Tmin, Tmin1, Tavg1, file_path)"
      ],
      "metadata": {
        "id": "CChC9XUIJ1Iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a39cd12-e301-464f-bd53-4390f19aea97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/13 [00:26<05:17, 26.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [01:51<11:11, 61.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [03:12<11:40, 70.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [04:32<11:04, 73.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [05:49<10:00, 75.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [07:07<08:52, 76.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [08:26<07:42, 77.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [09:44<06:27, 77.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [11:04<05:12, 78.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [12:25<03:57, 79.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [13:42<02:36, 78.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [15:00<01:18, 78.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [16:15<00:00, 75.02s/it]\n"
          ]
        }
      ]
    }
  ]
}